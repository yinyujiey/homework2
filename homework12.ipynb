{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "检测到的编码: utf-8\n",
      "文件读取成功\n",
      "国家分布:\n",
      " country\n",
      "United States     28136\n",
      "Canada            15612\n",
      "Germany           12983\n",
      "France             8581\n",
      "China              8135\n",
      "Netherlands        5574\n",
      "Norway             4513\n",
      "Poland             4496\n",
      "Italy              4240\n",
      "United Kingdom     4101\n",
      "Switzerland        3833\n",
      "Spain              3800\n",
      "Australia          3225\n",
      "Belgium            2610\n",
      "Slovenia           2589\n",
      "Sweden             2531\n",
      "Denmark            1668\n",
      "New Zealand        1366\n",
      "Lithuania          1186\n",
      "South Africa        973\n",
      "Israel              922\n",
      "Name: count, dtype: int64\n",
      "\n",
      "城市分布:\n",
      " location\n",
      "Oslo, Norway                      4513\n",
      "Zurich, Switzerland               3833\n",
      "Montreal, Québec, Canada          3779\n",
      "France                            3625\n",
      "Paris, France                     3356\n",
      "                                  ... \n",
      "Rome, Italy                        743\n",
      "Redmond, WA                        727\n",
      "北京                                 644\n",
      "Delaware (but Philly at heart)     599\n",
      "San Francisco                      485\n",
      "Name: count, Length: 77, dtype: int64\n",
      "\n",
      "提交频率:\n",
      " user_id\n",
      "81981       4513\n",
      "6961185     3779\n",
      "47313       3356\n",
      "74887181    2997\n",
      "3523016     2743\n",
      "            ... \n",
      "999278       743\n",
      "25274700     727\n",
      "3162115      644\n",
      "1609022      599\n",
      "3238291      485\n",
      "Name: count, Length: 81, dtype: int64\n",
      "\n",
      "活跃时间段:\n",
      " hour\n",
      "0     3691\n",
      "1     3072\n",
      "2     2846\n",
      "3     2556\n",
      "4     2511\n",
      "5     3037\n",
      "6     3984\n",
      "7     5778\n",
      "8     7508\n",
      "9     7766\n",
      "10    7341\n",
      "11    7085\n",
      "12    7498\n",
      "13    7859\n",
      "14    7705\n",
      "15    8174\n",
      "16    7174\n",
      "17    6473\n",
      "18    6152\n",
      "19    5530\n",
      "20    5800\n",
      "21    5563\n",
      "22    4595\n",
      "23    3874\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import chardet\n",
    "\n",
    "# 检测文件编码\n",
    "def detect_encoding(file_path):\n",
    "    with open(file_path, 'rb') as f:\n",
    "        result = chardet.detect(f.read())\n",
    "        encoding = result['encoding']\n",
    "        print(f\"检测到的编码: {encoding}\")\n",
    "        return encoding\n",
    "\n",
    "# 尝试读取CSV文件并处理异常\n",
    "def read_csv(file_path, encoding):\n",
    "    try:\n",
    "        df = pd.read_csv(file_path, encoding=encoding)  # 从CSV文件读取数据\n",
    "        print(\"文件读取成功\")\n",
    "        return df\n",
    "    except FileNotFoundError as e:\n",
    "        print(f\"文件未找到: {e}\")\n",
    "        exit()\n",
    "    except pd.errors.EmptyDataError as e:\n",
    "        print(f\"发现空数据: {e}\")\n",
    "        exit()\n",
    "    except UnicodeDecodeError as e:\n",
    "        print(f\"编码错误: {e}。尝试使用不同的编码重新读取文件。\")\n",
    "        exit()\n",
    "\n",
    "# 确保event_time列是datetime类型\n",
    "def ensure_datetime(df, column_name):\n",
    "    try:\n",
    "        df[column_name] = pd.to_datetime(df[column_name])\n",
    "    except ValueError as e:\n",
    "        print(f\"日期时间转换错误: {e}\")\n",
    "        exit()\n",
    "\n",
    "# 分析国家和地区分布\n",
    "def country_distribution(df):\n",
    "    country_distribution = df['country'].value_counts()\n",
    "    print(\"国家分布:\\n\", country_distribution)\n",
    "\n",
    "# 分析城市级别分布\n",
    "def city_distribution(df):\n",
    "    city_distribution = df['location'].value_counts()\n",
    "    print(\"\\n城市分布:\\n\", city_distribution)\n",
    "\n",
    "# 分析提交频率\n",
    "def submission_frequency(df):\n",
    "    submission_frequency = df['user_id'].value_counts()\n",
    "    print(\"\\n提交频率:\\n\", submission_frequency)\n",
    "\n",
    "# 分析活跃时间段\n",
    "def active_hours(df):\n",
    "    ensure_datetime(df, 'event_time')  # 确保event_time列是datetime类型\n",
    "    df['hour'] = df['event_time'].dt.hour\n",
    "    active_hours = df['hour'].value_counts().sort_index()\n",
    "    print(\"\\n活跃时间段:\\n\", active_hours)\n",
    "\n",
    "# 主函数\n",
    "def main():\n",
    "    file_path = 'C:/Users/y2209/Desktop/users_combined_info_500_part_7.csv'\n",
    "    encoding = detect_encoding(file_path)\n",
    "    \n",
    "    df = read_csv(file_path, encoding)\n",
    "    \n",
    "    country_distribution(df)\n",
    "    city_distribution(df)\n",
    "    submission_frequency(df)\n",
    "    active_hours(df)\n",
    "\n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "检测到的编码: utf-8\n",
      "文件读取成功\n",
      "国家分布已保存到CSV文件：C:/Users/y2209/Desktop/country_distribution.csv\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'city'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\core\\indexes\\base.py:3805\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3804\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3805\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3806\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32mindex.pyx:167\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mindex.pyx:196\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7081\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7089\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'city'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[16], line 81\u001b[0m\n\u001b[0;32m     78\u001b[0m     user_activity_over_time(df, output_dir \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124muser_activity_over_time.csv\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     80\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m---> 81\u001b[0m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[16], line 74\u001b[0m, in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m     72\u001b[0m \u001b[38;5;66;03m# 进行分析并保存结果\u001b[39;00m\n\u001b[0;32m     73\u001b[0m country_distribution(df, output_dir \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcountry_distribution.csv\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m---> 74\u001b[0m \u001b[43mcity_distribution\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_dir\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcity_distribution.csv\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     75\u001b[0m timezone_distribution(df, output_dir \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtimezone_distribution.csv\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     76\u001b[0m submission_frequency(df, output_dir \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msubmission_frequency.csv\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "Cell \u001b[1;32mIn[16], line 36\u001b[0m, in \u001b[0;36mcity_distribution\u001b[1;34m(df, output_path)\u001b[0m\n\u001b[0;32m     35\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcity_distribution\u001b[39m(df, output_path):\n\u001b[1;32m---> 36\u001b[0m     city_distribution \u001b[38;5;241m=\u001b[39m \u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcity\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mvalue_counts()\n\u001b[0;32m     37\u001b[0m     city_distribution\u001b[38;5;241m.\u001b[39mto_csv(output_path, header\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCount\u001b[39m\u001b[38;5;124m'\u001b[39m], index_label\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCity\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     38\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m城市分布已保存到CSV文件：\u001b[39m\u001b[38;5;132;01m{\u001b[39;00moutput_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\core\\frame.py:4102\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   4100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   4101\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> 4102\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4103\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   4104\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\core\\indexes\\base.py:3812\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3807\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[0;32m   3808\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[0;32m   3809\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[0;32m   3810\u001b[0m     ):\n\u001b[0;32m   3811\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[1;32m-> 3812\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m   3813\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m   3814\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3815\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3816\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3817\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'city'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import chardet\n",
    "\n",
    "# 检测文件编码\n",
    "def detect_encoding(file_path):\n",
    "    with open(file_path, 'rb') as f:\n",
    "        result = chardet.detect(f.read())\n",
    "        encoding = result['encoding']\n",
    "        print(f\"检测到的编码: {encoding}\")\n",
    "        return encoding\n",
    "\n",
    "# 尝试读取CSV文件并处理异常\n",
    "def read_csv(file_path, encoding):\n",
    "    try:\n",
    "        df = pd.read_csv(file_path, encoding=encoding)  # 从CSV文件读取数据\n",
    "        print(\"文件读取成功\")\n",
    "        return df\n",
    "    except FileNotFoundError as e:\n",
    "        print(f\"文件未找到: {e}\")\n",
    "        exit()\n",
    "    except pd.errors.EmptyDataError as e:\n",
    "        print(f\"发现空数据: {e}\")\n",
    "        exit()\n",
    "    except UnicodeDecodeError as e:\n",
    "        print(f\"编码错误: {e}。尝试使用不同的编码重新读取文件。\")\n",
    "        exit()\n",
    "\n",
    "# 国家和地区分布\n",
    "def country_distribution(df, output_path):\n",
    "    country_distribution = df['country'].value_counts()\n",
    "    country_distribution.to_csv(output_path, header=['Count'], index_label='Country')\n",
    "    print(f\"国家分布已保存到CSV文件：{output_path}\")\n",
    "\n",
    "# 城市级别分布\n",
    "def city_distribution(df, output_path):\n",
    "    city_distribution = df['location'].value_counts()\n",
    "    city_distribution.to_csv(output_path, header=['Count'], index_label='City')\n",
    "    print(f\"城市分布已保存到CSV文件：{output_path}\")\n",
    "\n",
    "\n",
    "\n",
    "# 提交频率\n",
    "def submission_frequency(df, output_path):\n",
    "    user_submission_frequency = df['user_id'].value_counts()\n",
    "    user_submission_frequency.to_csv(output_path, header=['Count'], index_label='User ID')\n",
    "    print(f\"提交频率已保存到CSV文件：{output_path}\")\n",
    "\n",
    "# 活跃时间段分析\n",
    "def active_hours(df, output_path):\n",
    "    df['event_time'] = pd.to_datetime(df['event_time'])\n",
    "    df['hour'] = df['event_time'].dt.hour\n",
    "    active_hours = df['hour'].value_counts().sort_index()\n",
    "    active_hours.to_csv(output_path, header=['Count'], index_label='Hour')\n",
    "    print(f\"活跃时间段已保存到CSV文件：{output_path}\")\n",
    "\n",
    "# 用户活跃度随时间变化\n",
    "def user_activity_over_time(df, output_path):\n",
    "    df['event_time'] = pd.to_datetime(df['event_time'])\n",
    "    user_activity_over_time = df.resample('M', on='event_time')['user_id'].count()\n",
    "    user_activity_over_time.to_csv(output_path, header=['Count'], index_label='Month')\n",
    "    print(f\"用户活跃度随时间变化已保存到CSV文件：{output_path}\")\n",
    "\n",
    "# 主函数\n",
    "def main():\n",
    "    file_path = 'C:/Users/y2209/Desktop/users_combined_info_500_part_1_output.csv'\n",
    "    output_dir = 'C:/Users/y2209/Desktop/'  # 输出文件的目录\n",
    "\n",
    "    # 检测编码并读取文件\n",
    "    encoding = detect_encoding(file_path)\n",
    "    df = read_csv(file_path, encoding)\n",
    "    \n",
    "    # 进行分析并保存结果\n",
    "    country_distribution(df, output_dir + 'country_distribution.csv')\n",
    "    city_distribution(df, output_dir + 'city_distribution.csv')\n",
    "    submission_frequency(df, output_dir + 'submission_frequency.csv')\n",
    "    active_hours(df, output_dir + 'active_hours.csv')\n",
    "    user_activity_over_time(df, output_dir + 'user_activity_over_time.csv')\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
